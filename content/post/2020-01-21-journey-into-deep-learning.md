---
title: Journey into Deep Learning
description: Better late than never
date: "2020-01-21"
categories:
- Learning
tags:
- AI
- Journey
draft: true
---

This is the learning journey that I wish I started earlier. But as the old saying goes, better late than never.

As usual, this post are my notes as I learn.

I found [interview with Emil Wallner](https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/) very inspiring and full of useful pointers where I could start. So off I go.

There are countless areas of research within Deep Learning, so I'm going to focus on Natural Language Processing (NLP) first, as it's something I've always been fascinated with (I wrote an NLP parser back in 2007 and spent a couple years thinking of the problem, but I wasn't a good enough coder back then to pull it off). Anyway, Stanford's [CS224n Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/) it is.

The amount of algebra in the course notes is daunting, and I have taken plenty of algebra and calculus in my degree (Telecom Engineering, basically a ton of signal theory). So I'm starting to think that I may need a more guided approach, a book or some lecture videos. I'd also like to be practising what I read, a more hands-on approach to all this. I'll stick to this lecture for a bit longer, read a few more and then decide.
